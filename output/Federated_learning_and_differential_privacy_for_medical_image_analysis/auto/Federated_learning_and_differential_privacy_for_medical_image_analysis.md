# Federated learning and diferential privacy for medical image analysis

Mohammed Adnan1,2,4, Shivam Kalra1,2, Jesse C. Cresswell3 , Graham W. Taylor2,4 & Hamid R. Tizhoosh1,2,5\*

The artifcial intelligence revolution has been spurred forward by the availability of large-scale datasets. In contrast, the paucity of large-scale medical datasets hinders the application of machine learning in healthcare. The lack of publicly available multi-centric and diverse datasets mainly stems from confdentiality and privacy concerns around sharing medical data. To demonstrate a feasible path forward in medical image imaging, we conduct a case study of applying a diferentially private federated learning framework for analysis of histopathology images, the largest and perhaps most complex medical images. We study the efects of IID and non-IID distributions along with the number of healthcare providers, i.e., hospitals and clinics, and the individual dataset sizes, using The Cancer Genome Atlas (TCGA) dataset, a public repository, to simulate a distributed environment. We empirically compare the performance of private, distributed training to conventional training and demonstrate that distributed training can achieve similar performance with strong privacy guarantees. We also study the efect of diferent source domains for histopathology images by evaluating the performance using external validation. Our work indicates that diferentially private federated learning is a viable and reliable framework for the collaborative development of machine learning models in medical image analysis.

Deep neural networks have achieved and established state-of-the-art results in many domains. However, deep learning models are data-intensive, i.e., they ofen require millions of training examples to learn efectively. Medical images may contain confdential and sensitive information about patients that ofen cannot be shared outside the institutions of their origin, especially when complete de-identifcation cannot be guaranteed. Te European General Data Protection Regulation (GDPR) and the United States Health Insurance Portability and Accountability Act (HIPAA) enforce guidelines and regulations for storing and exchanging personally identifable data and health data. Ethical guidelines also encourage respecting privacy, that is, the ability to retain complete control and secrecy about one’s personal information1 . As a result, large archives of medical data from various consortia remain widely untapped sources of information. For instance, histopathology images cannot be collected and shared in large quantities due to the aforementioned regulations, as well as due to data size constraints given their high resolution and gigapixel nature. Without sufcient and diverse datasets, deep models trained on histopathology images from one hospital may fail to generalize well on data from a diferent hospital (out-ofdistribution)2 . Te existence of bias or the lack of diversity in images from a single institution brings about the need for a collaborative approach which does not require data centralization. One way to overcome this problem is by collaborative data sharing (CDS) or federated learning among diferent hospitals3 .

In this paper, we explore federated learning (FL) as a collaborative learning paradigm, in which models can be trained across several institutions without explicitly sharing patient data. We study the impact of data distribution on the performance of FL, i.e., when hospitals have more or less data, and IID or non-IID data. We also show that using federated learning with additional privacy preservation techniques can improve the performance of histopathology image analysis compared to training without collaboration and quantitatively measure the privacy using Rényi Diferential Privacy Accountant4 . We discuss its benefts, drawbacks, potential weaknesses, as well as technical implementation considerations. Finally, we use lung cancer images from Te Cancer Genome Atlas (TCGA) dataset5 to construct a simulated environment of several institutions to validate our approach.

Federated learning (FL). Federated learning algorithms learn from decentralized data distributed across various client devices, in contrast to conventional learning algorithms. In most examples of FL, there is a centralized server which facilitates training a shared model and addresses critical issues such as data privacy, security, access rights, and heterogeneity6 . In FL, every client locally trains a copy of the centralized model, represented by the model weights $\omega$ , and reports its updates back to the server for aggregation across clients, without disclosing local private data. Mathematically, FL can be formulated as:

$$
\operatorname* { m i n } _ { \omega \in R } f ( \omega ) \quad { \mathrm { w i t h } } \quad f ( \omega ) = { \frac { 1 } { n } } \sum _ { i = 1 } ^ { n } f ( \omega ) ,
$$

where $f ( \omega )$ represents the total loss function over $n$ clients, and $f _ { i } ( \omega )$ represents the loss function with respect to client i’s local data. Te objective is to fnd weights $\omega$ that minimize the overall loss. McMahan et al.6 introduced federated averaging, or FedAvg (Algorithm 1), in which each client receives the current model $\omega _ { t }$ from the server, and computes $\nabla f _ { i } ( \omega _ { t } )$ , the average gradient of the loss function over its local data. Te gradients are used to update each client’s model weights using stochastic gradient descent (SGD) as $\omega _ { t + 1 } ^ { i }  \omega _ { t } - \eta \nabla f _ { i } ( \omega _ { t } )$ according to the learning rate $\eta$ . Next, the central server receives the updated weights $\begin{array} { r } { \omega _ { t + 1 } ^ { i }  \omega \sum \frac { n _ { i } } { n } \omega _ { t + 1 } ^ { i } , } \end{array}$ where $n$ is $t + 1$ i= from all participating clients and averages them to update the central model, $t + 1  \stackrel { \iota = 1 } { i = 1 } n$ the number of data points used by client i. To reduce communication costs, several local steps of SGD can be taken before communication and aggregation, however, this afects the convergence properties of FedAvg7 .

Other methods for FL have also been proposed. Yurochkin et al.8 proposed a Bayesian framework for FL. Claici et al.9 used KL divergence to fuse diferent models. Much work has also been done to improve the robustness of FL algorithms. Pillutla et al.10 proposed a robust and secure aggregation oracle based on the geometric median using a constant number of calls to a regular non-robust secure average oracle. Andrychowicz et al.11 proposed a meta-learning approach to coordinate the learning process in client/server distributed systems by using a recurrent neural network in the central server to learn how to optimally aggregate the gradients from the client models. Li et al.12 proposed a new framework for robust FL where the central server learns to detect and remove malicious updates using a spectral anomaly detection model, leading to targeted defense. Most of the algorithms cannot be directly compared or benchmarked as they address diferent problems in FL such as heterogeneity, privacy, adversarial robustness, etc. FedAvg is most commonly used because of its scalability to large datasets and comparable performance to other FL algorithms.

Federated learning in histopathology. FL is especially important for histopathology departments, as it facilitates collaboration among institutions without sharing private patient data. One prominent challenge when applying FL to medical images, and specifcally histopathology, is the problem of domain adaptation. Since most hospitals have diverse imaging methods and devices, images from a group of hospitals will be markedly diferent, and machine learning methods risk overftting to non-semantic diferences between them. Models trained using FL can sufer from serious performance drops when applied to images from previously unseen hospitals. Several recent works have explored applications of FL in histopathology, and grapple with this problem. Lu et al.13 demonstrated the feasibility and efectiveness of FL for a large-scale computational pathology studies. FedDG proposed by Liu et al.14 is a privacy-preserving solution to learn a generalizable FL model through an efective continuous frequency space interpolation mechanism across clients. Sharing frequency domain information enables the separation of semantic information from noise in the original images. Li et al.15 tackles the problem of domain adaptation with a physics-driven generative approach to disentangle the information about model and geometry from the imaging sensor6 .

<html><body><table><tr><td>Algorithm 1: FedAvg (or, Federated Averaging)'. There are n clients, B is the local minibatch size, E is the number of local epochs per communication round, n is the learning rate, and fi is the local loss function.</td></tr><tr><td>Server Executes</td></tr><tr><td>initialize ωo; for each round t = 0, 1, . . . do</td></tr><tr><td>for each client i = 0, . , n− 1 in parallel</td></tr><tr><td>ω ←ClientUpdate(i, ωi)</td></tr><tr><td>t+1 n nk k ωt+1 ← ∑i=1 n ω+1</td></tr><tr><td>ClientUpdate(i, ω): // Run on client i</td></tr><tr><td>for each local epoch e from 0, ..., E – 1 do</td></tr><tr><td>for each minibatch b of size B do</td></tr><tr><td>ωe+1 ← ωe − η∇ fi(ωe; b)</td></tr><tr><td>return ωE to server</td></tr></table></body></html>

Diferential privacy. While FL attempts to provide privacy by keeping private data on client devices, it does not provide a meaningful privacy guarantee. Updated model parameters are still sent from the clients to a centralized server, and these can contain private information16, such that even individual data points can be reconstructed17. Diferential privacy (DP) is a formal framework for quantifying the privacy that a protocol provides18. Te core idea of DP is that privacy should be viewed as a resource, something that is used up as information is extracted from a dataset. Te goal of private data analysis is to extract as much useful information as possible while consuming the least privacy. To formalize this concept, consider a database $D$ , which is simply a set of datapoints, and a probabilistic function $M$ acting on databases, called a mechanism. Te mechanism is said to be (ε, δ)-diferentially private if for all subsets of possible outputs $S \subseteq$ Range $( M )$ , and for all pairs of databases $D$ and $D ^ { \prime }$ that difer by one element,

$$
\operatorname* { P r } [ M ( D ) \in S ] \leq \exp ( \varepsilon ) \operatorname* { P r } [ M ( D ^ { \prime } ) \in S ] + \delta .
$$

When both ε and $\delta$ are small positive numbers, Eq. (2) implies that the outcomes of $M$ will be almost unchanged in distribution if one datapoint is changed in the database. In other words, adding one patient’s data to a diferentially private study will not afect the outcomes, with high probability.

Te advantage of DP is that it is quantitative. It yields a numerical guarantee on the amount of privacy that can be expected, in the stochastic sense, where lower $\varepsilon$ and $\delta$ implies that the mechanism preserves more privacy. Te framework also satisfes several useful properties. When multiple DP-mechanisms are composed, the total operation is also a DP-mechanism with well defned $\varepsilon$ and $\delta ^ { 1 9 }$ . Also, once the results of a DP-mechanism are known, no amount of post-processing can change the $( \varepsilon , \delta )$ guarantee20. Hence, while FL alone does not guarantee privacy, we can apply FL in conjunction with DP to give rigorous bounds on the amount of privacy aforded to clients and patients who participate in the collaboration.

Te simplest way to create a DP-mechanism is by adding Gaussian noise to the outcomes of a deterministic function with bounded sensitivity21. Tis method can be used in the context of training a machine learning model by clipping the norm of gradients to bound them, then adding noise, a process called diferentially private stochastic gradient descent (DP-SGD)22. McMahan et al.23 applied this at scale to FL.

Diferential privacy for medical imaging. Past works have noted the potential solution DP provides for machine learning in the healthcare domain. Kaissis et al.1 surveyed privacy-preservation techniques to be used in conjunction with machine learning, which were then implemented for classifying chest X-rays and segmenting CT scans24,25. In histopathology, Lu et al.13 reported DP guarantees for a neural network classifer trained with FL, following Li et al.26. Teir treatment involved adding Gaussian noise to trained model weights, however, neural networks weights do not have bounded sensitivity making their DP guarantee vacuous. A meaningful guarantee would require clipping the model weights before adding noise. We propose the more standard approach of DP-SGD, which clips gradient updates and adds noise, for use in histopathology.

Multiple instance learning (MIL). MIL is a type of supervised learning approach which uses a set of instances known as a bag. Instead of individual instances having an associated label, only the bag as a whole has one27. MIL is thus a natural candidate for learning to classify WSIs which must be broken into smaller representations due to size limitations. Permutation invariant operators for MIL were introduced by Tomczak et al.28 and successfully applied to digital pathology images. Isle et al.29 used MIL for digital pathology and introduced a diferent variety of MIL pooling functions, while Sudarshan et al.30 used MIL for histopathological breast cancer image classifcation. Graph neural networks (GNNs) have been used for MIL applications because of their permutation invariant characteristics. Tu et al.31 showed that GNNs can be used for MIL, where each instance acts as a node in a graph. Adnan et al.32 demonstrated an application of graph convolution neural networks to MIL in digital pathology and achieved state of the art accuracy on a lung sub cancer classifcation task.

# Method

Our proposed method (local to each client) consists of two steps, bag preparation and Multiple-Instance Learning (MIL). In the frst step, we extract multiple patches from the full-resolution WSI and create a mosaic (set) of patches. In the second step, we formulate the representation learning of WSIs as a set learning problem by applying a MEM model, an attention based MIL algorithm proposed by Kalra et al.33. Te MEM model is locally trained through DP-SGD to provide quantitative privacy bounds, and the local MEM models are centrally aggregated through FedAvg. In this section, we discuss the bag preparation step and MIL. An overview of the proposed method is visualized in Fig. 1.

Bag preparation. A patch selection method proposed by Kalra et  al.35 is used to extract representative patches (called mosaics) from each WSI. A sample WSI and its mosaic is illustrated in Fig. 2. Te steps involved in creations of a mosaic are: (1) removal of non-tissue regions using colour thresholding; (2) grouping the remaining tissue-containing patches into a pre-set number of categories through a clustering algorithm; and (3) randomly selecting a portion of all clustered patches (e.g., $1 0 \%$ ) within each cluster, yielding a mosaic. Te mosaic is transformed into a bag $X = x _ { 1 } ,$ ..., $x _ { n }$ for MIL, where $x _ { i }$ is the feature vector of the ith patch, obtained through a pre-trained feature extractor network. We use a DenseNet model for the feature extractor34. Each patch in the mosaic has size $1 0 0 0 \times 1 0 0 0$ pixels at $2 0 \times$ magnifcation ( $\mathrm { 0 . 5 \ : m p p }$ resolution).

MIL method. We used the MEM model proposed by Kalra et al.33 to get a single vector representation of all feature vectors of patches in a mosaic. MEM consists of memory units composed within a memory block. A memory block is the main component of MEM and produces a permutation invariant representation from a input sequence. Multiple memory blocks can be stacked together for modeling complex relationships and dependencies in set data. Te memory block is made of memory units and a bijective transformation unit shown in Fig. 3. A memory unit transforms an input sequence into an attention vector. A higher attention value represents a higher “importance” of the corresponding element of the input sequence. Essentially, it captures the relationships among diferent elements of the input. Multiple memory units enable the memory block to capture many complex dependencies and relationships among the elements. Each memory unit consists of an embedding matrix $\mathbf { A _ { i } }$ that transforms $\imath f \cdot$ -dimensional input vector $x _ { j }$ to a $d$ -dimensional memory vector $u _ { i j }$ according to

![](images/01bc55b0e02d613ea7ddd0949a7074e54eb92430cff67852dbb86fc6655fea54.jpg)  
Figure 1. Te proposed federated learning algorithm to train a MEM model33 for WSIs (disease) classifcation among multiple hospitals. Each client in FL is represented by a blue rectangle. Each client, frst transforms their local WSIs into mosaics (sets of representative patches). Te patches in each mosaic are converted to feature vectors using a DenseNet model34. Finally the sets of feature vectors are classifed using a MEM model. A shared central MEM model is trained using FedAvg6 among multiple clients (mimicking hospitals). Furthermore, $\mathrm { D P - S G D } ^ { 2 2 }$ is used for training the central MEM model with strict privacy bounds.

![](images/8304a9b87b83d7ee9b46f3d43fd1a97406df4c59d249cd11fd60b36330581012.jpg)  
Figure 2. Illustration of a sample WSI and its mosaic extracted using the approach in Kalra et al.35.

![](images/37ff368795b00a6205f952d12691a2e565f3d1129266ddd791ff44d3f933e78b.jpg)  
Figure 3. Schematic of a MEM model used for the classifcation of WSI mosaics. $X$ is an input sequence containing a number $n$ of $f$ -dimensional vectors. (a) Te memory block is a sequence-to-sequence model that takes $X$ and returns another sequence $\hat { X }$ . Te output $\hat { X }$ is a permutation-invariant representation of $X$ . A bijective transformation model (an autoencoder) converts the input $X$ to a permutation-equivariant sequence $C$ . Te weighted sum of $C$ is computed over diferent probability distributions $ { \boldsymbol { P } } _ { i }$ from memory units. Te hyperparameters of a memory block are (1) the dimensions of the bijective transformation $h$ , and (2) the number of memory units $m$ . (b) Te memory unit has $A _ { i } ,$ a trainable embedding matrix that transforms elements of $X$ to a $d$ -dimensional space (memories). Te output $ { \boldsymbol { P } } _ { i }$ is a probability distribution over the input $X ,$ , also known as attention. Te memory unit has a single hyper-parameter $d$ , i.e. the dimension of the embedding space33 $^ { \prime } \ast$ represents learnable parameters).

$$
u _ { i j } = \rho ( x _ { j } \mathbf { A _ { i } } ) ,
$$

where $\rho$ is some non-linearity. Te memory vectors are stacked to form a matrix $\mathbf { U _ { i } } { = } \left[ u _ { i 0 } , . . . , u _ { i n } \right]$ of shape $( n d )$ . Te relative degree of correlations among the memory vectors are computed using cross-correlation followed by a column-wise sofmax and then taking a row-wise average,

$$
\begin{array} { r l } & { S _ { i } = \mathrm { c o l u m n - w i s e - s o f t m a x } \Big ( \mathbf { U _ { i } U _ { i } ^ { T } } \Big ) , } \\ & { p _ { i } = \mathrm { r o w - w i s e - a v e r a g e } ( S _ { i } ) . } \end{array}
$$

Te $\mathbf { \nabla } _ { \mathbf { \ } } P _ { i }$ is the fnal output vector $( 1 n )$ from the ith memory unit $\bf { U _ { i } } ,$ as shown in Fig. 3. Te purpose of each memory unit is to embed feature vectors into another space that could correspond to a distinct “attribute” or “characteristic” of instances. Te cross correlation of the calculated attention vectors highlights instances which are highly suggestive of those attributes. Memory vectors are non-normalized as the magnitude may play an important role during the cross correlation.

In summary, a memory block is a sequence-to-sequence model, i.e., it transforms a given input sequence $X = x _ { 1 } , . . . , x _ { n }$ to another representative sequence $\hat { X } = \widehat { x _ { 1 } } , \ldots , \widehat { x _ { m } }$ . A memory block contains $m$ memory units, each of which takes sequential data as an input and generates an attention vector. Tese attention vectors are subsequently used to compute the fnal output sequence. By design, the output sequence is invariant to element-wise permutations of the input sequence as needed for MIL.

# Experiments and discussion

We validated the performance of FL for the classifcation of histopathology images using a simulated distributed environment and also using real-world hospital data. Previous studies have mostly experimented with a fxed number of clients having similar distributions of data1,13,36. Since real-world data is not necessarily IID, it is important to study the efect of non-IID data on the performance of FL, specifcally FedAvg. Furthermore, we provide a privacy analysis of the method through the diferential privacy framework, suggesting that FL can outperform non-collaborative training while maintaining a strong privacy guarantee.

In the frst experiment series, we vary the number of clients, with each client representing one hospital. To make our simulated environment better approach the non-IID real-world data, each client can have a diferent number of patients and a diferent distribution of cancer sub-types. In the second experiment series, we calculate the privacy bound of diferentially private FL using real-world hospital data. We used the available attributes in TCGA to divide the dataset across the tissue origin site (hospital) and created four client datasets as shown in Table 2.

Table 1. Evaluation on diferent data distributions. Centralized accuracy denotes the accuracy when the data is centralized. Te accuracy without FL is the mean and standard deviation of accuracy values across multiple clients without any collaboration. Te accuracy with FL is the mean and standard deviation of the central model trained at the end of FL evaluated on each client dataset.   

<html><body><table><tr><td rowspan="2">Data distribution</td><td rowspan="2">Number of clients n</td><td colspan="3">Accuracy</td></tr><tr><td>Without FL</td><td>With FL</td><td>Centralized</td></tr><tr><td rowspan="4">ID</td><td>4</td><td>0.731 ± 0.03</td><td>0.824 ± 0.02</td><td rowspan="4">0.848 ± 0.02</td></tr><tr><td>8</td><td>0.620± 0.06</td><td>0.780± 0.05</td></tr><tr><td>16</td><td>0.570±0.03</td><td>0.726 ± 0.06</td></tr><tr><td>32</td><td>0.527 ±0.02</td><td>0.641 ±0.09</td></tr><tr><td rowspan="4">Non IID</td><td>4</td><td>0.682± 0.10</td><td>0.824±0.01</td><td rowspan="4">0.848± 0.02</td></tr><tr><td>8</td><td>0.561 ± 0.08</td><td>0.823 ± 0.05</td></tr><tr><td>16</td><td>0.524±0.03</td><td>0.750 ± 0.06</td></tr><tr><td>32</td><td>0.520± 0.03</td><td>0.550±0.20</td></tr></table></body></html>

![](images/1227a000f7eaa4ba7cfda59258869ce117bee019bcb34c49c457084a5f3e3b76.jpg)  
Figure 4. Comparison of the mean accuracy across clients versus the accuracy of the central model trained with FL for the fabricated clients (not the real hospitals). Te accuracy is computed on two types of data distribution settings across clients—IID and Non-IID.

Lung cancer dataset—LUAD vs LUSC classifcation. Lung Adenocarcinoma (LUAD) and Lung Squamous Cell Carcinoma (LUSC) are two main sub-types of non-small cell lung cancer (NSCLC) that account for $6 5 \mathrm { - } 7 0 \%$ of all lung cancers37. An automated classifcation of these two main sub-types of NSCLC is a crucial step to assist pathologists for more informed diagnoses37,38. We obtained 2580 hematoxylin and eosin (H&E) stained WSIs of lung cancer from TCGA39, comprising about two TB of data. Te images were split into two groups of 1806 training, and 774 testing samples WSIs33. We transformed each raw image into a mosaic35, and then into a bag of features $X$ using a pre-trained DenseNet34. From the data, we carried out two experiment series by varying the parameters of FedAvg, or by varying the data distributions across clients. Tese experiment series are discussed as follows.

Experiment series 1—efect of number of clients and data distributions. We studied the efect of IID and non-IID distributions on the performance of FedAvg by randomly dividing the training images without replacement among diferent clients (hospitals). We also varied the number of clients $( n )$ while keeping the total number of images fxed. IID data is generated by uniformly dividing each cancer sub-type, i.e. LUAD and LUSC, among diferent clients. For each cancer sub-type, a probability distribution is created by assigning a random value to each client and then dividing it by the total sum. Subsequently, images are divided among diferent clients by sampling from the probability distribution. FL achieves superior performance for both IID and non-IID distributions of data compared to non-collaborative training. FL performs comparably to centralized training for reasonably sized datasets $( n = 4 , 8$ ). Results are summarized in Table 1 and Fig. 4. Te number of training samples for each client model is in Fig. 5.

We compared the performance with and without FedAvg for each setting. In total we tested 16 experimental settings in Table 1. In each of the experiments, the server model trained using FedAvg outperformed the models trained using local client datasets, showing the advantage of collaboration. As the total dataset is divided into smaller partitions for more clients, both client and server model performances deteriorate. We used SGD optimizer with learning rate $= 0 . 0 1$ . Te local epoch for each client was set to 1 and the server model was trained for 250 communication rounds. We visualize the relative improvement of FedAvg in Table 1.

![](images/9fc0bd880c5cddb8b640a13d88333c292d753a404253ede6036933eb498efb05.jpg)  
Figure 5. Visualisation of IID and non-IID distribution of data among client models.

Table 2. Source hospitals for test/train and external dataset and their data distribution.   

<html><body><table><tr><td>Dataset type</td><td>Source hospital (clients)</td><td>LUAD images</td><td>LUSC images</td><td>Total</td></tr><tr><td rowspan="4">Train/test</td><td>International Genomics Consortium</td><td>189</td><td>78</td><td>267</td></tr><tr><td>Indivumed</td><td>94</td><td>117</td><td>211</td></tr><tr><td>Asterand</td><td>90</td><td>117</td><td>207</td></tr><tr><td>Johns Hopkins</td><td>121</td><td>78</td><td>199</td></tr><tr><td rowspan="3">External</td><td>Christiana Healthcare</td><td>169</td><td>54</td><td>223</td></tr><tr><td>Roswell Park</td><td>35</td><td>75</td><td>110</td></tr><tr><td>Princess Margaret Hospital (Canada)</td><td>0</td><td>52</td><td>52</td></tr></table></body></html>

Table 3. Ablation study of DP hyperparameters (gradient clipping and noise multiplier).   

<html><body><table><tr><td>Gradient clipping</td><td>Noise multiplier</td><td>Privacy budget (ε)</td><td>Test accuracy</td><td>External accuracy</td></tr><tr><td>1.0</td><td>4</td><td>2.90</td><td>0.815</td><td>0.740</td></tr><tr><td>1.5</td><td>4</td><td>3.26</td><td>0.759</td><td>0.719</td></tr><tr><td>2.0</td><td>4</td><td>3.89</td><td>0.765</td><td>0.732</td></tr><tr><td>1.0</td><td>6.0</td><td>2.34</td><td>0.832</td><td>0.737</td></tr><tr><td>1.0</td><td>2.0</td><td>10.01</td><td>0.782</td><td>0.748</td></tr></table></body></html>

Experiment series 2—real‑world setting. In the second experiment series, we considered the efect of distributional diferences from diferent source hospitals, and a requirement to preserve privacy. Histopathology images can difer greatly, among others depending on the staining and imaging protocols of the source hospital. We selected seven hospitals from the TCGA dataset, four to act as clients in FL, and an additional three to provide externally collected data for model robustness testing. Te distribution of images by hospital is described in Table 2. For each of the four clients, we divided their available images in an 80:20 ratio for training and internal testing datasets, respectively. Ten we combined the images from the remaining three hospitals into a single external validation dataset to study the efects of distributions shifs on FedAvg.

In this experiment, we use Diferential Private Federated Learning (DP-FL) to ensure data privacy. Diferential Privacy (DP) was not considered in experiment series 1 since the objective was to study the efects of data size, distribution, and the number of clients on the performance of distributed learning/federated learning in general. In experiment series 2, we compared the performance of privacy-preserving FL training with both centralized training and non-collaborative training. In the FL training, the four hospitals act as clients collaborating to train one central model. Performance is evaluated on each client’s internal test set, as well as the external validation set. For comparison, we train a single model on the combined (centralized) training datasets which gives an upper bound on what could be achieved in the absence of privacy regulations. Finally, in the non-collaborative setting each client hospital trains their own model on only their own training dataset. We used DP-SGD to train the FL and combined models and computed the privacy guarantees $( \varepsilon , \delta )$ using a Rényi DP accountant4 . It was observed that the MEM model was sensitive to DP-SGD hyper parameters. We used a vectorized Adam optimizer40 with the following hyper-parameter values22: epochs $= 1 8 0$ , training set size $= 7 0 5$ , batch size $= 3 2$ , gradient clipping $\mathrm { n o r m } = 1 . 0 $ , Gaussian noise standard deviation $\phantom { - } . = 4 . 0$ , number of microbatches $= 3 2$ , learning rate $= 2 \times 1 0 ^ { - 5 }$ . Ablation study is provided in the Table 3.

As shown in Table 4, FL training achieves strong privacy bounds $\varepsilon = 2 . 9 0$ at $\delta = 0 . 0 0 0 1$ ) with better performance than non-collaborative training, comparable to centralized training. Tis demonstrates that FL could be efectively used in clinical settings to ensure data privacy with no signifcant degradation in performance. Results are shown in Table 4. FedAvg achieves comparable performance to centralized training without explicitly sharing private data with strong privacy guarantees. Due to distribution shifs, accuracy decreases on external validation for both Federated Learning and centralized training. Terefore, we experimentally demonstrate the Federated Learning can be used for medical image analysis in real-world setting without explicitly sharing data, while achieving similar performance to centralized training with data sharing.

# Conclusions

Tere is a vast reserve of knowledge in mass archives of clinical data held by hospitals which remains mostly untapped due to many confdentiality and privacy concerns. In this work, we proposed diferentially private federated learning as a potential method for learning from decentralized medical data such as histopathology images. Federated learning allows training models without explicitly sharing patient data and thus mitigates some confdentiality and privacy issues associated with clinical data. Diferential privacy supplements this with quantitative bounds on the amount of privacy provided. We demonstrated the efcacy of federated learning (FedAvg) with simulated real-world data, using both IID and non-IID data distributions. Private federated learning achieves a comparable result compared to conventional centralized training, and hence it could be considered for distributed training on medical data.

<html><body><table><tr><td rowspan="2">Source hospital</td><td colspan="2">Non-collaborative training</td><td colspan="2">DP-FEL training</td><td colspan="2">FL training</td><td colspan="2">Combined training</td></tr><tr><td>Test</td><td>External</td><td>Test</td><td>External</td><td>Test</td><td>External</td><td>Test</td><td>External</td></tr><tr><td>Interatieal mics</td><td>0.654</td><td>0.631</td><td rowspan="4">0.823 ± 0.01</td><td rowspan="4">0.707± 0.01</td><td rowspan="4">0.823± 0.01</td><td rowspan="4">0.741 ± 0.01</td><td rowspan="4">0.839 ± 0.01</td><td rowspan="4">0.768 ± 0.003</td></tr><tr><td>Indivumed</td><td>0.648</td><td>0.556</td></tr><tr><td>Asterand</td><td>0.709</td><td>0.701</td></tr><tr><td>John Hopkins</td><td>0.681</td><td>0.600</td></tr></table></body></html>

Table 4. Evaluation of collaborative and non-collaborative learning on Test and External Datasets using DP-SGD, achieving privacy parameter $\varepsilon = 2 . 9 0$ for $\delta { = } 0 . 0 0 0 1$ . For FL and combined training we report the mean accuracy and standard deviation across the client’s test datasets. On the external dataset we ran the experiments using three random initializations, and report the mean accuracy and standard deviation across them.

# Data availability

Te publicly available dataset of 30,072 WSIs from TCGA39 (Genomic Data Commons GDC) was used for conducting this study.

Received: 22 October 2021; Accepted: 13 January 2022   
Published online: 04 February 2022

# References

1. Kaissis, G. A., Makowski, M. R., Rückert, D. & Braren, R. F. Secure, privacy-preserving and federated machine learning in medical imaging. Nat. Mach. Intell. 2, 305–311 (2020) (Number: 6 Publisher: Nature Publishing Group).   
2. Aggarwal, R. et al. Diagnostic accuracy of deep learning in medical imaging: A systematic review and meta-analysis. NPJ Digital Med. 4, 1–23 (2021).   
3. Sheller, M. J. et al. Federated learning in medicine: Facilitating multi-institutional collaborations without sharing patient data. Sci. Rep. 10, 12598 (2020) (Number: 1 Publisher: Nature Publishing Group).   
4. Mironov, I. Rényi diferential privacy. in 2017 IEEE 30th Computer Security Foundations Symposium (CSF) (2017). https://doi.org/ 10.1109/CSF.2017.11.   
5. Weinstein, J. N. et al. Te cancer genome atlas pan-cancer analysis project. Nat. Genet. 45, 1113–1120 (2013).   
6. McMahan, B., Moore, E., Ramage, D., Hampson, S. & y Arcas, B. A. (eds.) Communication-efcient learning of deep networks from decentralized data. in Proceedings of the 20th International Conference on Artifcial Intelligence and Statistics, PMLR 54:1273–1282, 2017.   
7. Li, X., Huang, K., Yang, W., Wang, S. & Zhang, Z. On the Convergence of FedAvg on Non-IID Data. in International Conference on Learning Representations (2020). https://openreview.net/forum?id=HJxNAnVtDS. Accessed 11 Nov 2021.   
8. Yurochkin, M., Mayank, A., Soumya, G., Kristjan, G., Nghia, H., & Yasaman, K. Bayesian nonparametric federated learning of neural networks. in International Conference on Machine Learning, 7252–7261. (PMLR, 2019).   
9. Claici, S., Yurochkin, M., Ghosh, S. & Solomon, J. Model Fusion with Kullback–Leibler Divergence. arXiv:2007.06168 [cs, stat] (2020). http://arxiv.org/abs/2007.06168. ArXiv: 2007.06168.   
10. Pillutla, K., Kakade, S. M. & Harchaoui, Z. Robust Aggregation for Federated Learning. arXiv:1912.13445 [cs, stat] (2019). http:// arxiv.org/abs/1912.13445. ArXiv: 1912.13445.   
11. Andrychowicz, M. et al. Learning to learn by gradient descent by gradient descent. Diagn. Pathol. (2016, under review).   
12. Li, S., Cheng, Y., Wang, W., Liu, Y. & Chen, T. Learning to detect malicious clients for robust federated. Learning 2002, 00211 (2020).   
13. Lu, M. Y. et al. Federated learning for computational pathology on gigapixel whole slide images. arXiv preprint arXiv:2009.10190 (2020).   
14. Liu, Q., Chen, C., Qin, J., Dou, Q. & Heng, P.-A. FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space. in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 1013–1023 (2021).   
15. Li, D., Kar, A., Ravikumar, N., Frangi, A. F. & Fidler, S. Fed-Sim: Federated simulation for medical imaging. Diagn. Pathol. (2020, under review).   
16. Bhowmick, A., Duchi, J., Freudiger, J., Kapoor, G. & Rogers, R. Protection against reconstruction and its applications in private federated learning. arXiv preprint arXiv:1812.00984 (2018).   
17. Melis, L., Song, C., De Cristofaro, E. & Shmatikov, V. Exploiting unintended feature leakage in collaborative learning. in 2019 IEEE Symposium on Security and Privacy (SP), 691–706 (IEEE, 2019).   
18. Dwork, C., McSherry, F., Nissim, K. & Smith, A. Calibrating noise to sensitivity in private data analysis. In Teory of Cryptography (eds Halevi, S. & Rabin, T.) 265–284 (Springer, 2006).   
19. Dwork, C., Rothblum, G. N. & Vadhan, S. Boosting and diferential privacy. in 2010 IEEE 51st Annual Symposium on Foundations of Computer Science, 51–60 (IEEE, 2010).   
20. Dwork, C. & Roth, A. Te algorithmic foundations of diferential privacy. Found. Trends Teor. Comput. Sci. 9, 211–407. https:// doi.org/10.1561/0400000042 (2014).   
21. Dwork, C., Kenthapadi, K., McSherry, F., Mironov, I. & Naor, M. Our data, ourselves: privacy via distributed noise generation. in Advances in Cryptology (EUROCRYPT 2006), vol. 4004 of Lecture Notes in Computer Science, 486–503 (Springer Verlag, 2006). https://www.microsof.com/en-us/research/publication/our-data-ourselves-privacy-via-distributed-noise-generation/. Accessed 11 Nov 2021.   
22. Abadi, M. et al. Deep learning with diferential privacy. in Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security (2016). https://doi.org/10.1145/2976749.2978318.   
23. McMahan, H. B., Ramage, D., Talwar, K. & Zhang, L. Learning diferentially private recurrent language models. in International Conference on Learning Representations (2018).   
24. Kaissis, G. et al. End-to-end privacy preserving deep learning on multi-institutional medical imaging. Nat. Mach. Intell. 3, 473–484 (2021).   
25. Ziller, A. et al. Medical imaging deep learning with diferential privacy. Sci. Rep. 11, 1–8 (2021).   
26. Li, X. et al. Multi-site fMRI analysis using privacy-preserving federated learning and domain adaptation: ABIDE results. Med. Image Anal. 65, 101765 (2020).   
27. Carbonneau, M.-A., Cheplygina, V., Granger, E. & Gagnon, G. Multiple instance learning: A survey of problem characteristics and applications. Pattern Recognit. 77, 329–353 (2018).   
28. Tomczak, J. M., Ilse, M. & Welling, M. Deep learning with permutation-invariant operator for multi-instance histopathology classifcation. in Workshop on Bayesian Deep Learning at 31st Conference on Neural Information Processing Systems (2017). http:// arxiv.org/abs/1712.00310.   
29. Ilse, M., Tomczak, J. & Welling, M. Attention-based deep multiple instance learning. in International conference on machine learning, 2127–2136 (PMLR, 2018).   
30. Sudharshan, P. et al. Multiple instance learning for histopathological breast cancer image classifcation. Expert Syst. Appl. 117, 103–111 (2019).   
31. Tu, M., Huang, J., He, X. & Zhou, B. Multiple instance learning with graph neural networks. in ICML 2019 Workshop on Learning and Reasoning with Graph-Structured Representations (2019). http://arxiv.org/abs/1906.04881.   
32. Adnan, M., Kalra, S. & Tizhoosh, H. R. Representation learning of histopathology images using graph neural networks. in 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 4254–4261 (2020).   
33. Kalra, S., Adnan, M., Taylor, G. & Tizhoosh, H. R. Learning permutation invariant representations using memory networks. in European Conference on Computer Vision, 677–693 (Springer, 2020).   
34. Huang, G., Liu, Z., Van Der Maaten, L. & Weinberger, K. Q. Densely connected convolutional networks. in Proceedings of the IEEE conference on computer vision and pattern recognition, 4700–4708 (2017).   
35. Kalra, S. et al. Yottixel—An image search engine for large archives of histopathology whole slide images. Med. Image Anal. 65, 101757 (2020).   
36. Chang, K. et al. Distributed deep learning networks among institutions for medical imaging. J. Am. Med. Inform. Assoc. 25, 945–954 (2018).   
37. Zappa, C. & Mousa, S. A. Non-small cell lung cancer: Current treatment and future advances. Transl. Lung Cancer Res. 5, 288 (2016).   
38. Graham, S., Muhammad, S., Talha, Q., Navid Alemi K., Syed Ali K., & Nasir, R. Classifcation of lung cancer histology images using patch-level summary statistics. in Medical Imaging : Digital Pathology, vol. 10581, 1058119 (International Society for Optics and Photonics, 2018).   
39. Tomczak, K., Czerwinska, P. & Wiznerowicz, M. Te Cancer Genome Atlas (TCGA): An immeasurable source of knowledge. Contemp. Oncol. 19, A68 (2015).   
40. Subramani, P., Vadivelu, N. & Kamath, G. Enabling fast diferentially private sgd via just-in-time compilation and vectorization. Diagn. Pathol. (2020, under review).

# Acknowledgements

We would like to thank the Ontario Government for awarding an ORF-RE grant for this project (Ontario Research Fund Research Excellence) (ORF-RE Gigapixel Identifcation-Tizhoosh). Te frst author is supported by a Vector Institute internship. Te basic research of the corresponding author leading to this work has been supported by Te Natural Sciences and Engineering Research Council of Canada (NSERC) through multiple Discovery Grants. For access to computational and storage facilities, we would like to thank Compute Canada.

# Author contributions

M.A. designed and conducted the experiments, and wrote the frst draf of the paper. S.K. helped in designing the datasets, fgures experimental setup, and provided important edits to the paper. J.C.C. was involved in the discussion, contributed to the diferential privacy analysis of the method, reviewed the code, and provided important edits to the paper. G.W.T. and H.R.T. were involved in the discussions of the approach, and provided critical feedback to the paper. H.R.T. guided the external validations with TCGA images.

# Competing interests

Te authors declare no competing interests.

# Additional information

Correspondence and requests for materials should be addressed to H.R.T.

Reprints and permissions information is available at www.nature.com/reprints.

Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional afliations.

Open Access Tis article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. Te images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.

$^ ©$ Te Author(s) 2022